from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse
import uvicorn
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array, load_img
import io
from PIL import Image
import autokeras as ak
from datetime import datetime
import csv
import os
import pandas as pd
import shutil
import uuid
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
from s3_utils import upload_to_s3

app = FastAPI()

def generate_gradcam(model, img_array, last_conv_layer_name="conv2d"):
    # ëª¨ë¸ì˜ ë§ˆì§€ë§‰ Conv layerë¡œë¶€í„° Grad-CAM ê³„ì‚°
    grad_model = tf.keras.models.Model(
        [model.inputs],
        [model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        loss = predictions[:, 0]

    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # ì •ê·œí™”
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    heatmap = heatmap.numpy()

    return heatmap

# ğŸ”§ ëª¨ë¸ ë¡œë“œ
MODEL_PATH = r"C:\Users\Admin\Desktop\smart_factory_qa\models\best_model.h5"
model = load_model(MODEL_PATH, custom_objects=ak.CUSTOM_OBJECTS)
image_size = (300, 300)

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # ì´ë¯¸ì§€ ì½ê¸° ë° ì „ì²˜ë¦¬
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")
        image = image.resize(image_size)
        image = img_to_array(image) / 255.0
        image = np.expand_dims(image, axis=0)  # (1, 300, 300, 3)

        # ì˜ˆì¸¡
        prediction = model.predict(image)[0][0]
        label = "ì •ìƒ" if prediction >= 0.5 else "ë¶ˆëŸ‰"
        prob = round(float(prediction), 4)
        
        # ğŸ”„ ì´ë¯¸ì§€ ë¶„ë¥˜ ì €ì¥
        save_root = r"C:\Users\Admin\Desktop\smart_factory_qa\sorted"
        base_label = "ok" if label == "ì •ìƒ" else "defect"
        original_dir = os.path.join(save_root, base_label, "original")
        gradcam_dir = os.path.join(save_root, base_label, "gradcam")
        os.makedirs(original_dir, exist_ok=True)
        os.makedirs(gradcam_dir, exist_ok=True)

        # ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ timestampì™€ ë™ì¼:
        ext = os.path.splitext(file.filename)[-1]
        timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(original_dir, f"{timestamp_str}{ext}")

        # ì´ë¯¸ì§€ ë‚´ìš©ì„ ì €ì¥
        with open(save_path, "wb") as out_file:
            out_file.write(contents)
            
        # ğŸ”¥ Grad-CAM íˆíŠ¸ë§µ ìƒì„± (ì´ê±´ ë”°ë¡œ!)
        heatmap = generate_gradcam(model, image)
        heatmap = cv2.resize(heatmap, image_size)
        heatmap = np.uint8(255 * heatmap)

        original = np.array(Image.open(io.BytesIO(contents)).resize(image_size).convert("RGB"))
        heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        superimposed_img = cv2.addWeighted(original, 0.6, heatmap_color, 0.4, 0)

        # ì €ì¥
        cam_path = os.path.join(gradcam_dir, f"cam_{timestamp_str}.jpeg")
        cv2.imwrite(cam_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))
        
        # ğŸ”„ ê²°ê³¼ ì—‘ì…€ ì €ì¥ (ì—‘ì…€ ì—´ë ¤ìˆì„ ê²½ìš° log.txtì— ê¸°ë¡)
        excel_path = r"C:\Users\Admin\Desktop\smart_factory_qa\results\results.xlsx"
        timestamp_now = datetime.now()

        new_row = pd.DataFrame([{
            "timestamp": timestamp_now.strftime("%Y-%m-%d %H:%M:%S"),
            "filename": file.filename,
            "prediction": label,
            "probability": prob
        }])

        try:
            if os.path.exists(excel_path):
                existing_df = pd.read_excel(excel_path, engine='openpyxl')
                updated_df = pd.concat([existing_df, new_row], ignore_index=True)
            else:
                updated_df = new_row

            updated_df.to_excel(excel_path, index=False, engine='openpyxl')

        except PermissionError:
            log_path = r"C:\Users\Admin\Desktop\smart_factory_qa\log.txt"
            with open(log_path, "a", encoding="utf-8") as logf:
                logf.write(f"[{timestamp_now}] âŒ ì—‘ì…€ ê¸°ë¡ ì‹¤íŒ¨ - íŒŒì¼ ì—´ë ¤ ìˆìŒ: {file.filename}\n")

        

        # (ì˜ˆì¸¡ê³¼ ì €ì¥ ëë‚œ í›„ì—)
        BUCKET_NAME = "smart-factory-datalake"

        # ğŸ”¼ Excel ì—…ë¡œë“œ
        upload_to_s3(excel_path, BUCKET_NAME, "classification/results")

        # ğŸ”¼ ì´ë¯¸ì§€ ì—…ë¡œë“œ (original + shap í•˜ìœ„ í´ë” í¬í•¨)
        upload_to_s3(original_dir, BUCKET_NAME, f"classification/sorted/{base_label}/original")
        upload_to_s3(gradcam_dir, BUCKET_NAME, f"classification/sorted/{base_label}/gradcam")
        
        return JSONResponse(content={
            "filename": file.filename,
            "prediction": label,
            "probability": f"{prob:.2%}"
        })
        
        
            
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})
    
