#!/usr/bin/env python
# coding: utf-8

# In[1]:


# âœ… S3 ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ PostgreSQLì— ë“±ë¡í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
# ëª©ì : def_front/, ok_front/ ì´ë¯¸ì§€ â†’ uploads + input_image í…Œì´ë¸” ìë™ ì ì¬

import boto3
import psycopg2
import io
from PIL import Image
from datetime import datetime

# ---------------------- ì„¤ì • ----------------------
AWS_ACCESS_KEY = 'AKIA2UMF2NRTTGTVHHUD'
AWS_SECRET_KEY = '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'
BUCKET_NAME = 'smart-factory-datalake'

DB_INFO = {
    "host": "localhost",
    "dbname": "postgres",
    "user": "postgres",
    "password": "0523",
    "port": 5432,
}

S3_PREFIXES = {
    "def_front/": True,   # ë¶ˆëŸ‰ ì´ë¯¸ì§€ (is_defect=True)
    "ok_front/": False    # ì •ìƒ ì´ë¯¸ì§€ (is_defect=False)
}

# ---------------------- S3 ë° DB ì—°ê²° ----------------------
s3 = boto3.client("s3", aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)
conn = psycopg2.connect(**DB_INFO)
cur = conn.cursor()

# ---------------------- uploads í…Œì´ë¸” ë“±ë¡ ----------------------
cur.execute("""
    INSERT INTO uploads (company_id, uploader_id, file_key, has_target, label_type)
    VALUES (%s, %s, %s, TRUE, 'binary')
    RETURNING upload_id
""", (
    '11111111-1111-1111-1111-111111111111',
    '22222222-2222-2222-2222-222222222222',
    'manual_upload/def_ok_front/'
))
upload_id = cur.fetchone()[0]
print(f"\nğŸŸ¢ Upload ID ìƒì„±ë¨: {upload_id}\n")

# ---------------------- ì´ë¯¸ì§€ ë“±ë¡ ----------------------
for prefix, is_defect in S3_PREFIXES.items():
    paginator = s3.get_paginator("list_objects_v2")
    for page in paginator.paginate(Bucket=BUCKET_NAME, Prefix=prefix):
        for obj in page.get("Contents", []):
            key = obj["Key"]
            if key.endswith("/"): continue  # ë””ë ‰í† ë¦¬ ë¬´ì‹œ

            try:
                response = s3.get_object(Bucket=BUCKET_NAME, Key=key)
                image = Image.open(io.BytesIO(response["Body"].read()))
                width, height = image.size
                fmt = image.format

                cur.execute("""
                    INSERT INTO input_image (upload_id, image_path, width, height, format, is_defect)
                    VALUES (%s, %s, %s, %s, %s, %s)
                """, (upload_id, key, width, height, fmt, is_defect))

                print(f"âœ… ë“±ë¡ ì™„ë£Œ: {key} ({'ë¶ˆëŸ‰' if is_defect else 'ì •ìƒ'})")

            except Exception as e:
                print(f"âš ï¸ ì‹¤íŒ¨: {key} â†’ {e}")

# ---------------------- ì™„ë£Œ ì²˜ë¦¬ ----------------------
conn.commit()
cur.close()
conn.close()
print("\nğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


# In[ ]:


# âœ… ì²˜ìŒ input? -> yes ì¸ ê²½ìš°ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì½”ë“œ
# S3ì—ì„œ ì´ë¯¸ì§€ ì„ íƒ -> DB ì €ì¥ -> ëª¨ë¸ íƒìƒ‰/ë“±ë¡ê¹Œì§€ í¬í•¨ (ìƒ˜í”Œë§ í¬í•¨)

import os
import io
import boto3
import psycopg2
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from datetime import datetime
import tensorflow as tf
import autokeras as ak
import mlflow
import mlflow.keras
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, roc_auc_score, accuracy_score

# -------------------- ì„¤ì • --------------------

AWS_ACCESS_KEY = 'AKIA2UMF2NRTTGTVHHUD'
AWS_SECRET_KEY = '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'
BUCKET_NAME = 'smart-factory-datalake'

DB_INFO = {
    'host': 'localhost',
    'port': 5432,
    'dbname': 'postgres',
    'user': 'postgres',
    'password': '0523'
}

image_size = (300, 300)
sample_size = 3000
s3 = boto3.client("s3", aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_KEY)

def fetch_latest_upload_id():
    conn = psycopg2.connect(**DB_INFO)
    cur = conn.cursor()
    cur.execute("""
        SELECT upload_id FROM uploads
        WHERE label_type = 'binary'
        ORDER BY created_at DESC
        LIMIT 1
    """)
    result = cur.fetchone()
    cur.close()
    conn.close()
    if not result:
        raise Exception("âŒ binary íƒ€ì…ì˜ upload_idê°€ ì—†ìŠµë‹ˆë‹¤.")
    return result[0]

def fetch_sampled_images(upload_id, sample_size):
    print(f"\nğŸŸ¢ DBì—ì„œ upload_id={upload_id} ë°ì´í„° ë¡œë”© ì¤‘")
    conn = psycopg2.connect(**DB_INFO)
    df = pd.read_sql("""
        SELECT id AS image_id, image_path, is_defect
        FROM input_image
        WHERE upload_id = %s
    """, conn, params=(upload_id,))
    present_classes = set(df["is_defect"].unique())
    if len(present_classes) < 2:
        missing_class = 1 if 0 in present_classes else 0
        print(f"âš ï¸ í´ë˜ìŠ¤ {missing_class} ë³´ì™„ì„ ìœ„í•´ DBì—ì„œ ì¶”ê°€ ì¡°íšŒ")
        df_add = pd.read_sql(f"""
            SELECT id AS image_id, image_path, is_defect
            FROM input_image
            WHERE is_defect = {missing_class} AND upload_id != %s
            ORDER BY RANDOM()
            LIMIT 10
        """, conn, params=(upload_id,))
        df = pd.concat([df, df_add], ignore_index=True)
    conn.close()
    if df.empty:
        raise ValueError(f"âŒ upload_id {upload_id}ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    df_sampled = df.sample(n=min(sample_size, len(df)), random_state=42).reset_index(drop=True)
    print(f"âœ… ìƒ˜í”Œë§ ì™„ë£Œ: {len(df_sampled)}ê°œ (ë‘ í´ë˜ìŠ¤ í¬í•¨ë¨)")
    x, y = [], []
    for _, row in tqdm(df_sampled.iterrows(), total=len(df_sampled), desc="ğŸ“¦ ì´ë¯¸ì§€ ë¡œë”©"):
        try:
            key = row["image_path"]
            label = int(row["is_defect"])
            obj = s3.get_object(Bucket=BUCKET_NAME, Key=key)
            img = Image.open(io.BytesIO(obj["Body"].read())).convert("RGB").resize(image_size)
            x.append(np.array(img) / 255.0)
            y.append(label)
        except Exception as e:
            print(f"âš ï¸ {key} â†’ {e}")
    return np.array(x, dtype=np.float32), np.array(y, dtype=np.int32)

def train_and_register_model(upload_id):
    x, y = fetch_sampled_images(upload_id, sample_size)
    if len(np.unique(y)) < 2:
        print("âŒ í´ë˜ìŠ¤ê°€ í•˜ë‚˜ì…ë‹ˆë‹¤. í•™ìŠµ ìƒëµ")
        return
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)

    clf = ak.ImageClassifier(overwrite=True, max_trials=1)
    clf.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))

    try:
        y_pred_probs = clf.predict(x_test).flatten()
    except:
        y_pred_probs = clf.predict(x_test)
    y_pred = np.round(y_pred_probs).astype(int)

    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_probs)

    mlflow.set_tracking_uri("http://localhost:5000")
    mlflow.set_experiment("SmartFactory_Image_Models")

    with mlflow.start_run() as run:
        model = clf.export_model()
        mlflow.keras.log_model(model, "model")
        mlflow.log_metrics({"accuracy": accuracy, "f1_score": f1, "auc_score": auc})

        conn = psycopg2.connect(**DB_INFO)
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO model_registry (
                mlflow_run_id, trained_on_upload_id,
                accuracy, f1_score, auc_score, is_active, created_at
            ) VALUES (%s, %s, %s, %s, %s, TRUE, NOW())
        """, (run.info.run_id, upload_id, accuracy, f1, auc))
        conn.commit()
        conn.close()
    print("âœ… ëª¨ë¸ ë“±ë¡ ì™„ë£Œ")

if __name__ == "__main__":
    upload_id = fetch_latest_upload_id()
    train_and_register_model(upload_id)

